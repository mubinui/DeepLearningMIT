{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralNetworkMIT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO1f3dzgv3tkGRxa+pNbPgF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mubinui/DeepLearningMIT/blob/main/NeuralNetworkMIT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uS1ErITM6UMG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "import tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dense Layer from the scratch"
      ],
      "metadata": {
        "id": "TpGZlIBJEN0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDenseLayer(tf.keras.layers.Layer):\n",
        "\n",
        "\n",
        "    def __init__ (self, input_dim, output_dim):\n",
        "        super(MyDenseLayer, self).__init__()\n",
        "\n",
        "        #Initializing the weights and bias\n",
        "        self.W = self.add_weight([input_dim, output_dim])\n",
        "        self.b = self.add_weight([1, output_dim])\n",
        "\n",
        "        def call(self, inputs):\n",
        "            #Forward propagate the inputs \n",
        "            z = tf.matmul(inputs, self.W) + self.b\n",
        "\n",
        "            #Feed through a non-linear activation\n",
        "            output = tf.math.sigmoid(z)\n",
        "\n",
        "            return output \n"
      ],
      "metadata": {
        "id": "40J6fxsZ-OZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The built in methods in tensorflow\n",
        "Here in our case two inputs "
      ],
      "metadata": {
        "id": "cyH1UgzyF6_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer = tf.keras.layers.Dense(units=2)\n"
      ],
      "metadata": {
        "id": "P6_drhp6-Tnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here is a neural network with a hidden layer\n",
        "# Dense layer means fully connected layers \n",
        "# Last layer defines how many outputs we have \n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(n),\n",
        "    tf.keras.layers.Dense(2)\n",
        "])"
      ],
      "metadata": {
        "id": "dz7iwfv0GvKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying neural Network \n",
        "<br>\n",
        "<b>Example Problem :</b> Will I pass the class ? \n",
        "<br>  x1 = Number of lectures you attend\n",
        "<br> x2 = Hours spent on the final project   "
      ],
      "metadata": {
        "id": "F9yL0yOkHrMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = [4,5]"
      ],
      "metadata": {
        "id": "hcmPMEkmHZ3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantifying the Loss\n",
        "<br>\n",
        "Emperical Loss\n",
        "*   Actual - Predicted \n",
        "\n",
        "\n",
        "Loss Optimization \n",
        "\n"
      ],
      "metadata": {
        "id": "FpNNs3o-JDNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "604NZM3zK4OF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gradient Descent Algorithm\n",
        "Algorithm \n",
        "<br> 1. Initialize the weights randomly \n",
        "<br> 2. Loop until convergence \n",
        "<br> 3. Compute gradient \n",
        "<br> 4. Update weights \n",
        "<br> 5. Return weights "
      ],
      "metadata": {
        "id": "Cj6HjcNPK5Mk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "weights = tf.Variable([tf.random.normal()])\n",
        "while True: # Loop forever\n",
        "    with tf.GradientTape() as g:\n",
        "        loss = compute_loss(weights)\n",
        "        gradient = g.gradient(loss, weights)\n",
        "    weights = weights - lr * gradient "
      ],
      "metadata": {
        "id": "2QdMh6cILbjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Recurrent Neural Network "
      ],
      "metadata": {
        "id": "Sm-VPZacWsHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_rnn = RNN()\n",
        "hidden_state = [0, 0, 0, 0]\n",
        "sentence = [\"I\", \"love\", \"recurrent\", \"neural\"]"
      ],
      "metadata": {
        "id": "6cM6k8Xpyinr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}